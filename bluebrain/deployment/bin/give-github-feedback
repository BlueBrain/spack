#!/bin/sh
# vim: filetype=python
""":"
# Provides some feedback to a Github pull request about installed software
# and testing procedures
#
# In the spirit of Spack, this first docstring is executed by the shell and
# launches the appropriate Python setup
MY_VENV=$(mktemp -d)/venv
trap "rm -rf '${MY_VENV}'" EXIT
python3 -mvenv "${MY_VENV}"
. "${MY_VENV}/bin/activate"
pip install requests pyyaml jinja2 lxml
exec python3 $0
# Error out if the above fails
exit 1
":"""

import fnmatch
import io
import json
import os
import requests
import yaml
import zipfile
from copy import copy
from glob import glob
from jinja2 import Environment, BaseLoader
from lxml import etree
from pprint import pprint


COMMENT_TEMPLATE = """
{%- if failed_stages -%}
The following build jobs of the deployment for this PR failed:
{% for name, link in failed_stages -%}
* [{{name}}]({{link}})
{% endfor %}
{% else -%}
To test your PR, use the following on BlueBrain5:
```shell
unset MODULEPATH
. {{deployment_root}}/config/modules.sh
module load unstable
```
{% if updated_modules -%}
Please test the following updated modules:
{% for module in updated_modules -%}
* `{{module}}`
{% endfor %}
{% endif -%}
{% if failed_builds -%}
Please fix the following packages that failed to build:
{% for name, sha, link in failed_builds -%}
* [`{{name}}` ({{sha}})]({{link}})
{% endfor %}
{% endif -%}
{% endif -%}
{% if failed_tests -%}
The following module tests failed:
{% for name, link in failed_tests -%}
* [{{name}}]({{link}})
{% endfor -%}
{%- endif -%}
"""


def gather_updated_modules(basedir):
    build_shas = set()
    for filename in glob(f"{basedir}/*/.spack-db/index.json"):
        with open(filename) as fd:
            data = json.load(fd).get("database", {})
            build_shas.update(data.get("installs", {}).keys())
    for filename in glob(f"{basedir}/*/modules*/module-index.yaml"):
        with open(filename) as fd:
            data = yaml.safe_load(fd).get("module_index", {})
        for sha in build_shas:
            if sha in data:
                yield data[sha]["use_name"]


def github_api_post(url, payload):
    auth_user = os.environ.get("GITHUB_API_USER_OVERRIDE", "")
    if not len(auth_user):
        auth_user = "bbpbuildbot"
    auth_token = os.environ.get("GITHUB_API_KEY_OVERRIDE", "")
    if not len(auth_token):
        auth_token = os.environ["GITHUB_API_KEY"]
    return requests.post(
        url,
        data=json.dumps(payload),
        auth=(auth_user, auth_token),
        headers={"Accept": "application/vnd.github.v3+json"},
    )


def gitlab_api_post(url, json=True):
    auth_token = os.environ["GITLAB_API_KEY"]
    response = requests.get(url, headers={"PRIVATE-TOKEN": auth_token})
    response.raise_for_status()
    if json:
        return response.json()
    else:
        return response.content


def query(what, project=None, json=True):
    project = project or os.environ["CI_PROJECT_ID"]
    api_url = os.environ["CI_API_V4_URL"]
    url = "{0}/projects/{1}/{2}".format(api_url, project, what)
    return gitlab_api_post(url, json=json)


def get_bridges(pipeline):
    return query("pipelines/{0}/bridges".format(pipeline))


def get_jobs(pipeline, project=None):
    """Returns the first page of the jobs for a pipeline."""
    q = "pipelines/{0}/jobs".format(pipeline)
    return query(q, project)


def get_jobs_with_tests(pipeline):
    """Returns the deployment jobs that build stuff."""
    for job in get_jobs(pipeline):
        stage = job["stage"]
        jid = job["id"]
        if stage == job["name"]:
            name = job["name"]
        else:
            name = " / ".join([stage, job["name"]])
        status = job["status"]
        url = job["web_url"]
        junit = False
        for fragment in job["artifacts"]:
            if fragment["file_type"] == "junit":
                junit = True
        yield (jid, name, stage, status, url, junit)


def get_real_pipeline():
    for j in get_bridges(os.environ["CI_PIPELINE_ID"]):
        info = j["downstream_pipeline"]
        if str(info["project_id"]) == os.environ["CI_PROJECT_ID"]:
            return info["id"]
    raise KeyError()


def get_junit(job, stage):
    what = "jobs/{0}/artifacts".format(job)
    data = query(what, json=False)
    q = "spack_tests/{0}/*.xml".format(stage)
    with zipfile.ZipFile(io.BytesIO(data)) as zf:
        for fn in zf.namelist():
            if fnmatch.fnmatch(fn, q) and not fn.endswith("fake.xml"):
                yield zf.open(fn).read()


def get_build_failures(pipeline):
    failed_jobs = set()
    failed_builds = dict()

    for (
        job_id,
        job_name,
        job_stage,
        job_status,
        job_url,
        job_junit,
    ) in get_jobs_with_tests(pipeline):
        if job_status == "failed":
            failed_jobs.add((job_name, job_url))
        if job_junit:
            print("Processing JUnit of", job_name)
            for data in get_junit(job_id, job_stage):
                tree = etree.fromstring(data)
                for failed in tree.xpath("//failure/ancestor::testcase"):
                    output = next(failed.iterchildren("failure"))
                    print("Found build failure for", failed.get("classname"))
                    failed_builds[
                        (failed.get("classname"), failed.get("name"))
                    ] = output.text
    return (
        sorted(failed_jobs),
        sorted((n, i, v) for (n, i), v in failed_builds.items())
    )


def get_module_test_failures(pipeline):
    for j in get_bridges(pipeline):
        if j["name"] == "check_modules":
            break
    else:
        raise KeyError()
    test_pipe = j["downstream_pipeline"]
    if test_pipe:
        for j in get_jobs(test_pipe["id"], project=test_pipe["project_id"]):
            if j["status"] == "failed":
                yield (j["name"], j["web_url"])


def post_pipeline_info():
    repo = os.environ["GITHUB_REPOSITORY"]
    pr = os.environ["GITHUB_PULL_REQUEST_ID"]
    deployment_root = os.environ["DEPLOYMENT_ROOT"]

    updated_modules = list(gather_updated_modules(deployment_root))

    # Use this when triggering from a parent pipeline
    # pipe = get_real_pipeline()
    pipe = os.environ["CI_PIPELINE_ID"]
    failed_stages, raw_failed_builds = get_build_failures(pipe)
    failed_module_tests = sorted(get_module_test_failures(pipe))

    pprint(raw_failed_builds)
    failed_builds = []
    for name, sha, log in raw_failed_builds:
        failed_builds.append((name, sha, "NOPE"))
    print("Failed builds to pass on to GitHub:")
    pprint(failed_builds)

    data = (
        Environment(loader=BaseLoader)
        .from_string(COMMENT_TEMPLATE)
        .render(
            failed_stages=failed_stages,
            failed_builds=failed_builds,
            failed_tests=failed_module_tests,
            updated_modules=updated_modules,
            deployment_root=deployment_root,
        )
    )
    print("Posting a comment to the GitHub PR...")
    comment_request = github_api_post(
        "https://api.github.com/repos/{repo}/issues/{pr}/comments".format(repo=repo, pr=pr),
        {"body": data},
    )
    pprint(comment_request.json())
    print(":wave:")


if __name__ == "__main__":
    post_pipeline_info()
